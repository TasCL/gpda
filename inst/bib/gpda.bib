% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Beaumont2010,
  Title                    = {Approximate {Bayesian} {Computation} in {Evolution} and {Ecology}},
  Author                   = {Beaumont, Mark A.},
  Journal                  = {Annual Review of Ecology, Evolution, and Systematics},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {379--406},
  Volume                   = {41},

  Abstract                 = {In the past 10years a statistical technique, approximate Bayesian computation (ABC), has been developed that can be used to infer parameters and choose between models in the complicated scenarios that are often considered in the environmental sciences. For example, based on gene sequence and microsatellite data, the method has been used to choose between competing models of human demographic history as well as to infer growth rates, times of divergence, and other parameters. The method fits naturally in the Bayesian inferential framework, and a brief overview is given of the key concepts. Three main approaches to ABC have been developed, and these are described and compared. Although the method arose in population genetics, ABC is increasingly used in other fields, including epidemiology, systems biology, ecology, and agent-based modeling, and many of these applications are briefly described.},
  Doi                      = {10.1146/annurev-ecolsys-102209-144621},
  File                     = {Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/AIEQE8JG/2010 - Approximate Bayesian Computation in Evolution and .pdf:application/pdf},
  Url                      = {http://dx.doi.org/10.1146/annurev-ecolsys-102209-144621},
  Urldate                  = {2017-03-09}
}

@Article{Braak2006,
  Title                    = {A Markov Chain Monte Carlo version of the genetic algorithm Differential Evolution: easy Bayesian computing for real parameter spaces},
  Author                   = {Braak, Cajo J. F. Ter},
  Journal                  = {Statistics and Computing},
  Year                     = {2006},
  Number                   = {3},
  Pages                    = {239--249},
  Volume                   = {16},

  Abstract                 = {Differential Evolution (DE) is a simple genetic algorithm for numerical optimization in real parameter spaces. In a statistical context one would not just want the optimum but also its uncertainty. The uncertainty distribution can be obtained by a Bayesian analysis (after specifying prior and likelihood) using Markov Chain Monte Carlo (MCMC) simulation. This paper integrates the essential ideas of DE and MCMC, resulting in Differential Evolution Markov Chain (DE-MC). DE-MC is a population MCMC algorithm, in which multiple chains are run in parallel. DE-MC solves an important problem in MCMC, namely that of choosing an appropriate scale and orientation for the jumping distribution. In DE-MC the jumps are simply a fixed multiple of the differences of two random parameter vectors that are currently in the population. The selection process of DE-MC works via the usual Metropolis ratio which defines the probability with which a proposal is accepted. In tests with known uncertainty distributions, the efficiency of DE-MC with respect to random walk Metropolis with optimal multivariate Normal jumps ranged from 68{\%} for small population sizes to 100{\%} for large population sizes and even to 500{\%} for the 97.5{\%} point of a variable from a 50-dimensional Student distribution. Two Bayesian examples illustrate the potential of DE-MC in practice. DE-MC is shown to facilitate multidimensional updates in a multi-chain ``Metropolis-within-Gibbs'' sampling approach. The advantage of DE-MC over conventional MCMC are simplicity, speed of calculation and convergence, even for nearly collinear parameters and multimodal densities.},
  Doi                      = {10.1007/s11222-006-8769-1},
  ISSN                     = {1573-1375},
  Owner                    = {yslin},
  Timestamp                = {2017.03.10},
  Url                      = {http://dx.doi.org/10.1007/s11222-006-8769-1}
}

@Article{Brown2008,
  Title                    = {The simplest complete model of choice response time: linear ballistic accumulation},
  Author                   = {Brown, Scott D and Heathcote, Andrew},
  Journal                  = {Cognitive Psychology},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {153--178},
  Volume                   = {57},

  Doi                      = {doi:10.1016/j.cogpsych.2007.12.002},
  File                     = {ScienceDirect Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/PAGCKJUK/Brown and Heathcote - 2008 - The simplest complete model of choice response tim.pdf:application/pdf;ScienceDirect Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/Z3CRZ3DU/S0010028507000722.html:text/html;ScienceDirect Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/AB39NVMW/S0010028507000722.html:text/html},
  Keywords                 = {Choice, Decision, Lexical decision, Mathematical models, Reaction Time, Response time}
}

@Article{Dawson1988,
  Title                    = {Fitting the ex-{Gaussian} equation to reaction time distributions},
  Author                   = {Dawson, Michael R. W.},
  Journal                  = {Behavior Research Methods, Instruments, \& Computers},
  Year                     = {1988},

  Month                    = jan,
  Number                   = {1},
  Pages                    = {54--57},
  Volume                   = {20},

  Abstract                 = {Two programs that can be used to determine the probability distributions of reaction times are detailed. The first program takes rank-ordered reaction times as input and outputs a file of quantized data. The second program uses a simplex procedure to estimate the parameters of the ex-Gaussian equation that provides the best description of the quantized data. The advantages of this type of data analysis are also discussed.},
  Doi                      = {10.3758/BF03202603},
  File                     = {Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/9UD9V5AM/Dawson - 1988 - Fitting the ex-Gaussian equation to reaction time .pdf:application/pdf;Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/J6G2HBVQ/BF03202603.html:text/html},
  ISSN                     = {0743-3808, 1532-5970},
  Language                 = {en},
  Url                      = {https://link.springer.com/article/10.3758/BF03202603},
  Urldate                  = {2017-03-09}
}

@Book{gelman_bayesian_2014,
  Title                    = {Bayesian data analysis},
  Author                   = {Gelman, Andrew},
  Publisher                = {CRC Press},
  Year                     = {2014},

  Address                  = {Boca Raton},
  Note                     = {OCLC: 864304245},

  ISBN                     = {978-1-4398-4095-5 978-1-4398-4096-2},
  Language                 = {English}
}

@Article{hoffman2014_nut,
  Title                    = {The no-u-turn sampler: {Adaptively} setting path lengths in {Hamiltonian} {Monte} {Carlo}},
  Author                   = {Hoffman, Matthew D. and Gelman, Andrew},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {15},

  Abstract                 = {Hierarchical Bayesian models are a mainstay of the machine learning and statistics communities. Exact posterior inference in such models is rarely tractable, so researchers and practitioners must usually resort to approximate inference methods. Perhaps the most popular class of approximate posterior inference algorithms, Markov Chain Monte Carlo (MCMC) methods offer schemes for},
  File                     = {Citeseer - Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/ZBVEJ72Z/Hoffman and Gelman - 2011 - The no-u-turn sampler Adaptively setting path len.pdf:application/pdf;Citeseer - Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/RSJW6ZFP/summary.html:text/html},
  Shorttitle               = {The no-u-turn sampler}
}

@Article{Hohle1965,
  Title                    = {Inferred components of reaction times as functions of foreperiod duration},
  Author                   = {Hohle, Raymond H.},
  Journal                  = {Journal of Experimental Psychology},
  Year                     = {1965},
  Number                   = {4},
  Pages                    = {382--386},
  Volume                   = {69},

  Abstract                 = {A distribution function representing simple reaction-time distributions was derived, assuming {RT} is the sum of 2 component variables with exponential and normal distributions. 4 Ss each gave 100 {RTs} to an auditory stimulus following each of 4 foreperiods, under each of 2 conditions: (a) foreperiod constant within sessions but varied over sessions, and (b) foreperiods appearing in a random sequence. The derived distribution function provided completely satisfactory representations of all 32 {RT} distributions, and the relations of the fitted parameters of this function to foreperiod suggest that the variation of {RT} as a function of foreperiod is due to variation in the normally distributed component.},
  Copyright                = {(c) 2012 {APA}, all rights reserved},
  Doi                      = {10.1037/h0021740},
  ISSN                     = {0022-1015(Print)},
  Keywords                 = {*Reaction Time, Stimulus Duration},
  Owner                    = {yslin},
  Timestamp                = {2017.05.10}
}

@Article{Holmes2015,
  Title                    = {A practical guide to the {Probability} {Density} {Approximation} ({PDA}) with improved implementation and error characterization},
  Author                   = {Holmes, William R.},
  Journal                  = {Journal of Mathematical Psychology},
  Year                     = {2015},

  Month                    = oct,
  Pages                    = {13--24},
  Volume                   = {68--69},

  Abstract                 = {A critical task in modeling is to determine how well the theoretical assumptions encoded in a model account for observations. Bayesian methods are an ideal framework for doing just this. Existing approximate Bayesian computation (ABC) methods however rely on often insufficient “summary statistics”. Here, I present and analyze a highly efficient extension of the recently proposed (Turner and Sederberg 2014) Probability Density Approximation (PDA) method, which circumvents this insufficiency. This method combines Markov Chain Monte Carlo simulation with tools from non-parametric statistics to improve upon existing ABC methods. The primary contributions of this article are: (1) A more efficient implementation of this method that substantially improves computational performance is described. (2) Theoretical results describing the influence of methodological approximation errors on posterior estimation are discussed. In particular, while this method is highly accurate, even small errors have a strong influence on model comparisons when using standard statistical approaches (such as deviance information criterion). (3) An augmentation of the standard PDA procedure, termed “resampled PDA”, that reduces the negative influence of approximation errors on performance and accuracy, is presented. (4) A number of examples of varying complexity are presented along with supplementary code for their implementation.},
  Doi                      = {10.1016/j.jmp.2015.08.006},
  File                     = {ScienceDirect Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/K6GJHC6Z/Holmes - 2015 - A practical guide to the Probability Density Appro.pdf:application/pdf;ScienceDirect Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/2HKE7SKE/S0022249615000541.html:text/html},
  Keywords                 = {Approximate likelihood, Kernel density estimate, Linear ballistic accumulator model, Markov chain Monte Carlo, Non-parametric approximate Bayesian computation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0022249615000541},
  Urldate                  = {2017-01-09}
}

@Article{Holmes2016,
  Title                    = {A new framework for modeling decisions about changing information: The Piecewise Linear Ballistic Accumulator model },
  Author                   = {William R. Holmes and Jennifer S. Trueblood and Andrew Heathcote},
  Journal                  = {Cognitive Psychology },
  Year                     = {2016},
  Pages                    = {1 - 29},
  Volume                   = {85},

  Abstract                 = {Abstract In the real world, decision making processes must be able to integrate non-stationary information that changes systematically while the decision is in progress. Although theories of decision making have traditionally been applied to paradigms with stationary information, non-stationary stimuli are now of increasing theoretical interest. We use a random-dot motion paradigm along with cognitive modeling to investigate how the decision process is updated when a stimulus changes. Participants viewed a cloud of moving dots, where the motion switched directions midway through some trials, and were asked to determine the direction of motion. Behavioral results revealed a strong delay effect: after presentation of the initial motion direction there is a substantial time delay before the changed motion information is integrated into the decision process. To further investigate the underlying changes in the decision process, we developed a Piecewise Linear Ballistic Accumulator model (PLBA). The \{PLBA\} is efficient to simulate, enabling it to be fit to participant choice and response-time distribution data in a hierarchal modeling framework using a non-parametric approximate Bayesian algorithm. Consistent with behavioral results, \{PLBA\} fits confirmed the presence of a long delay between presentation and integration of new stimulus information, but did not support increased response caution in reaction to the change. We also found the decision process was not veridical, as symmetric stimulus change had an asymmetric effect on the rate of evidence accumulation. Thus, the perceptual decision process was slow to react to, and underestimated, new contrary motion information. },
  Doi                      = {https://doi.org/10.1016/j.cogpsych.2015.11.002},
  ISSN                     = {0010-0285},
  Keywords                 = {Evidence accumulation models},
  Owner                    = {yslin},
  Timestamp                = {2017.05.10},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0010028515000912}
}

@Article{Kristan2011,
  Title                    = {Multivariate online kernel density estimation with Gaussian kernels },
  Author                   = {Matej Kristan and Aleš Leonardis and Danijel Skočaj},
  Journal                  = {Pattern Recognition },
  Year                     = {2011},
  Note                     = {Semi-Supervised Learning for Visual Content Analysis and Understanding },
  Number                   = {10–11},
  Pages                    = {2630 - 2642},
  Volume                   = {44},

  Abstract                 = {We propose a novel approach to online estimation of probability density functions, which is based on kernel density estimation (KDE). The method maintains and updates a non-parametric model of the observed data, from which the \{KDE\} can be calculated. We propose an online bandwidth estimation approach and a compression/revitalization scheme which maintains the KDE's complexity low. We compare the proposed online \{KDE\} to the state-of-the-art approaches on examples of estimating stationary and non-stationary distributions, and on examples of classification. The results show that the online \{KDE\} outperforms or achieves a comparable performance to the state-of-the-art and produces models with a significantly lower complexity while allowing online adaptation. },
  Doi                      = {https://doi.org/10.1016/j.patcog.2011.03.019},
  ISSN                     = {0031-3203},
  Keywords                 = {Online models},
  Owner                    = {yslin},
  Timestamp                = {2017.05.08},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0031320311001233}
}

@Article{Matzke2009,
  Title                    = {Psychological interpretation of the ex-Gaussian and shifted Wald parameters: A diffusion model analysis},
  Author                   = {Matzke, Dora and Wagenmakers, Eric-Jan},
  Journal                  = {Psychonomic Bulletin \& Review},
  Year                     = {2009},

  Month                    = oct,
  Number                   = {5},
  Pages                    = {798--817},
  Volume                   = {16},

  Abstract                 = {A growing number of researchers use descriptive distributions such as the ex-Gaussian and the shifted Wald to summarize response time data for speeded two-choice tasks. Some of these researchers also assume that the parameters of these distributions uniquely correspond to specific cognitive processes. We studied the validity of this cognitive interpretation by relating the parameters of the ex-Gaussian and shifted Wald distributions to those of the Ratcliff diffusion model, a successful model whose parameters have well-established cognitive interpretations. In a simulation study, we fitted the ex-Gaussian and shifted Wald distributions to data generated from the diffusion model by systematically varying its parameters across a wide range of plausible values. In an empirical study, the two descriptive distributions were fitted to published data that featured manipulations of task difficulty, response caution, and a priori bias. The results clearly demonstrate that the ex-Gaussian and shifted Wald parameters do not correspond uniquely to parameters of the diffusion model. We conclude that researchers should resist the temptation to interpret changes in the ex-Gaussian and shifted Wald parameters in terms of cognitive processes. Supporting materials may be downloaded from http://pbr.psychonomic-journals .org/content/supplemental.},
  Doi                      = {10.3758/PBR.16.5.798},
  File                     = {Full Text PDF:C\:\\Users\\user\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\8lsp7iop.default\\zotero\\storage\\CPTH5Q9X\\Matzke and Wagenmakers - 2009 - Psychological interpretation of the ex-Gaussian an.pdf:application/pdf;Snapshot:C\:\\Users\\user\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\8lsp7iop.default\\zotero\\storage\\9XR2FX2K\\PBR.16.5.html:text/html},
  ISSN                     = {1069-9384, 1531-5320},
  Keywords                 = {Cognitive Psychology},
  Language                 = {en},
  Owner                    = {yslin},
  Shorttitle               = {Psychological interpretation of the ex-Gaussian and shifted Wald parameters},
  Timestamp                = {2017.05.10},
  Url                      = {http://link.springer.com/article/10.3758/PBR.16.5.798},
  Urldate                  = {2014-06-04}
}

@Article{McClelland1979,
  Title                    = {On the time relations of mental processes: {An} examination of systems of processes in cascade},
  Author                   = {McClelland, James L.},
  Journal                  = {Psychological Review},
  Year                     = {1979},

  Month                    = jul,
  Number                   = {4},
  Pages                    = {287--330},
  Volume                   = {86},

  __markedentry            = {[yslin:]},
  Abstract                 = {Examines the possibility that the components of an information-processing system all operate continuously, passing information from one to the next as it becomes available. A model called the "cascade model" is presented and shown to be compatible with the general form of the relation between time and accuracy in speed-accuracy trade-off experiments. In the model, experimental manipulations may have either or both of 2 effects on a processing level: They may alter the rate of response or the asymptotic quality of the output. The effects of such manipulations on the output of a system of processes is described. The model is then used to reexamine the subtraction and additive factors methods for analyzing the composition of systems of processes. Results include the finding that factors that affect the rates of 2 different processes would be expected to have additive effects on reaction times under the cascade model, whereas 2 factors that both affect the rate of the same process would tend to interact, just as in the case in which the manipulations affect the durations of discrete stages. Factors that affect asymptotic output, however, tend to interact whether they affect the same or different processes. A new method is presented for analyzing processes in cascade, which extends the additive factors method to an analysis of the parameters of the function relating response time and accuracy. (70 ref) (PsycINFO Database Record (c) 2006 APA, all rights reserved), (C) 1979 by the American Psychological Association},
  ISSN                     = {0033-295X},
  Keywords                 = {cascade model of information processing},
  Language                 = {English.},
  Owner                    = {yslin},
  Shorttitle               = {On the time relations of mental processes},
  Timestamp                = {2017.05.11}
}

@Article{Parzen1962,
  Title                    = {On Estimation of a Probability Density Function and Mode},
  Author                   = {Parzen, Emanuel},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1962},

  Month                    = {09},
  Number                   = {3},
  Pages                    = {1065--1076},
  Volume                   = {33},

  Doi                      = {10.1214/aoms/1177704472},
  Fjournal                 = {The Annals of Mathematical Statistics},
  Owner                    = {yslin},
  Publisher                = {The Institute of Mathematical Statistics},
  Timestamp                = {2017.05.09},
  Url                      = {http://dx.doi.org/10.1214/aoms/1177704472}
}

@Article{Ratcliff2008,
  Title                    = {The {Diffusion} {Decision} {Model}: {Theory} and {Data} for {Two}-{Choice} {Decision} {Tasks}},
  Author                   = {Ratcliff, Roger and McKoon, Gail},
  Journal                  = {Neural Computation},
  Year                     = {2008},

  Month                    = apr,
  Number                   = {4},
  Pages                    = {873--922},
  Volume                   = {20},

  __markedentry            = {[yslin:6]},
  Abstract                 = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data—accuracy, mean response times, and response time distributions—into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
  Doi                      = {10.1162/neco.2008.12-06-420},
  File                     = {IEEE Xplore Abstract Record:files/86/freeabs_all.html:text/html},
  ISSN                     = {0899-7667},
  Owner                    = {yslin},
  Shorttitle               = {The {Diffusion} {Decision} {Model}},
  Timestamp                = {2017.05.12}
}

@Article{sanderson_armadillo:_2016,
  Title                    = {Armadillo: a template-based {C}++ library for linear algebra},
  Author                   = {Sanderson, Conrad and Curtin, Ryan},
  Journal                  = {The Journal of Open Source Software},
  Year                     = {2016},

  Month                    = jun,
  Number                   = {2},
  Volume                   = {1},

  Doi                      = {10.21105/joss.00026},
  Shorttitle               = {Armadillo},
  Url                      = {http://joss.theoj.org/papers/10.21105/joss.00026},
  Urldate                  = {2017-03-09}
}

@Book{silverman_density_1986,
  Title                    = {Density estimation for statistics and data analysis},
  Author                   = {Silverman, Bernard W},
  Publisher                = {CRC press},
  Year                     = {1986},
  Volume                   = {26}
}

@Article{Sisson2010,
  Title                    = {Likelihood-free {Markov} chain {Monte} {Carlo}},
  Author                   = {Sisson, S. A. and Fan, Y.},
  Journal                  = {arXiv:1001.2058 [stat]},
  Year                     = {2010},

  Month                    = jan,
  Note                     = {arXiv: 1001.2058},

  Abstract                 = {To appear to MCMC handbook, S. P. Brooks, A. Gelman, G. Jones and X.-L. Meng (eds), Chapman \& Hall.},
  File                     = {arXiv\:1001.2058 PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/29ZWJNE5/Sisson and Fan - 2010 - Likelihood-free Markov chain Monte Carlo.pdf:application/pdf;arXiv.org Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/GQACJXXU/1001.html:text/html},
  Keywords                 = {Statistics - Methodology},
  Url                      = {http://arxiv.org/abs/1001.2058},
  Urldate                  = {2017-03-09}
}

@Article{Turner2013,
  Title                    = {Likelihood-free {Bayesian} analysis of memory models},
  Author                   = {Turner, Brandon M. and Dennis, Simon and Van Zandt, Trisha},
  Journal                  = {Psychological Review},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {667--678},
  Volume                   = {120},

  Abstract                 = {Many influential memory models are computational in the sense that their predictions are derived through simulation. This means that it is difficult or impossible to write down a probability distribution or likelihood that characterizes the random behavior of the data as a function of the model’s parameters. In turn, the lack of a likelihood means that these models cannot be directly fitted to data using traditional techniques. In particular, standard Bayesian analyses of such models are impossible. In this article, we examine how a new procedure called approximate Bayesian computation (ABC), a method for Bayesian analysis that circumvents the evaluation of the likelihood, can be used to fit computational models to memory data. In particular, we investigate the bind cue decide model of episodic memory (Dennis \& Humphreys, 2001) and the retrieving effectively from memory model (Shiffrin \& Steyvers, 1997). We fit hierarchical versions of each model to the data of Dennis, Lee, and Kinnell (2008) and Kinnell and Dennis (2012). The ABC analysis permits us to explore the relationships between the parameters in each model as well as evaluate their relative fits to data—analyses that were not previously possible.},
  Copyright                = {(c) 2016 APA, all rights reserved},
  Doi                      = {10.1037/a0032458},
  ISSN                     = {1939-1471 0033-295X},
  Keywords                 = {*Computational Modeling, *Memory, *Models, *Simulation, Statistical Probability},
  Language                 = {English},
  Owner                    = {yslin},
  Timestamp                = {2017.03.10}
}

@Article{Turner2014,
  Title                    = {A generalized, likelihood-free method for posterior estimation},
  Author                   = {Turner, Brandon M. and Sederberg, Per B.},
  Journal                  = {Psychonomic Bulletin \& Review},
  Year                     = {2014},

  Month                    = apr,
  Number                   = {2},
  Pages                    = {227--250},
  Volume                   = {21},

  Abstract                 = {Recent advancements in Bayesian modeling have allowed for likelihood-free posterior estimation. Such estimation techniques are crucial to the understanding of simulation-based models, whose likelihood functions may be difficult or even impossible to derive. However, current approaches are limited by their dependence on sufficient statistics and/or tolerance thresholds. In this article, we provide a new approach that requires no summary statistics, error terms, or thresholds and is generalizable to all models in psychology that can be simulated. We use our algorithm to fit a variety of cognitive models with known likelihood functions to ensure the accuracy of our approach. We then apply our method to two real-world examples to illustrate the types of complex problems our method solves. In the first example, we fit an error-correcting criterion model of signal detection, whose criterion dynamically adjusts after every trial. We then fit two models of choice response time to experimental data: the linear ballistic accumulator model, which has a known likelihood, and the leaky competing accumulator model, whose likelihood is intractable. The estimated posterior distributions of the two models allow for direct parameter interpretation and model comparison by means of conventional Bayesian statistics—a feat that was not previously possible.},
  Doi                      = {10.3758/s13423-013-0530-0},
  File                     = {Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/HWE5B3X8/Turner and Sederberg - 2014 - A generalized, likelihood-free method for posterio.pdf:application/pdf;Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/2D4UKPPC/s13423-013-0530-0.html:text/html},
  ISSN                     = {1069-9384, 1531-5320},
  Language                 = {en},
  Url                      = {https://link.springer.com/article/10.3758/s13423-013-0530-0},
  Urldate                  = {2017-03-09}
}

@Article{VanZandt2000,
  Title                    = {How to fit a response time distribution},
  Author                   = {Van Zandt, Trisha},
  Journal                  = {Psychonomic Bulletin {\&} Review},
  Year                     = {2000},
  Number                   = {3},
  Pages                    = {424--465},
  Volume                   = {7},

  Abstract                 = {Among the most valuable tools in behavioral science is statistically fitting mathematical models of cognition to data---response time distributions, in particular. However, techniques for fitting distributions vary widely, and little is known about the efficacy of different techniques. In this article, we assess several fitting techniques by simulating six widely cited models of response time and using the fitting procedures to recover model parameters. The techniques include the maximization of likelihood and least squares fits of the theoretical distributions to different empirical estimates of the simulated distributions. A running example is used to illustrate the different estimation and fitting procedures. The simulation studies reveal that empirical density estimates are biased even for very large sample sizes. Some fitting techniques yield more accurate and less variable parameter estimates than do others. Methods that involve least squares fits to density estimates generally yield very poor parameter estimates.},
  Doi                      = {10.3758/BF03214357},
  ISSN                     = {1531-5320},
  Owner                    = {yslin},
  Timestamp                = {2017.05.09},
  Url                      = {http://dx.doi.org/10.3758/BF03214357}
}

