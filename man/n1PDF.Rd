% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/density.R
\name{n1PDF}
\alias{n1PDF}
\title{Approximate Node 1 Density of a Canonical LBA Model}
\usage{
n1PDF(x, nsim = 1024, b = 1, A = 0.5, mean_v = c(2.4, 1.6),
  sd_v = c(1, 1), t0 = 0.5, nthread = 64, h = NA, debug = FALSE)
}
\arguments{
\item{x}{a numeric vector for estimating likelihood.}

\item{nsim}{number of Monte Carlo simulations for building a simulated PDF. 
This must be a power of two.}

\item{b}{decision threshold. Default is 1.}

\item{A}{start point variability. Because the LBA model draws
realisation of start point from an uniform distribution, \code{A} is the 
upper bound of the uniform distribution. See the below reference for 
more details.}

\item{mean_v}{mean drift rate. This must be a two-element numeric vector.}

\item{sd_v}{standard deviation of the drift rate. This must be a two-element 
numeric vector. The LBA model draws realisation of drift rate for a trial 
from a normal distribution. \code{n1PDF} draws from a truncated normal 
distribution, eliminating realisation of negative drift rate.  Note in 
the canonical LBA model, mean drift rate could be negative, but not 
drift-rate realisation .}

\item{t0}{nondecision time.}

\item{nthread}{number of GPU threads launched per block. Default is 32. 
Maximum thread per block is 1024 for K80 and 512 for most early GPU cards.}

\item{h}{kernal density bandwidth}

\item{debug}{a debugging switch. This is for advance users who wish to use 
CUDA C API.}
}
\value{
a numeric likelihood vector.
}
\description{
This is the probability density function for the canonical 2-accumualtor LBA 
model, sampling drift rates from truncated normal distributions. The 
function approximates model likelihood, instead of calculating analytically.
}
\examples{
##### n1PDF examples 
data <- seq(0, 3, length.out = 1e3);

## Default parameters are b = 1, A = 0.5, mean_v = c(2.4, 1.6),
## sd_v = c(1, 1), t0 = 0.5 with nthread = 32 and nsim = 1024 
den1 <- gpda::n1PDF(data)

## Raising nsim to 2^20 can improve approximation
den2 <- gpda::n1PDF(data, nsim=2^20)
plot(data,  den2, type="l")
lines(data, den1, lwd=1.5)

\dontrun{
den3 <- rtdists::n1PDF(data, b=1, A=.5, mean_v=c(2.4, 1.6), sd_v=c(1, 1), 
                       t0=.5, silent=T)
lines(data, den3, lwd=2)
all.equal(den1, den3)
all.equal(den2, den3)
## "Mean relative difference: 0.1675376"
## "Mean relative difference: 0.007108101"
}

##### An extreme case that rlba does not match dlba 
## When approximated PDF is almost perfect with 2^20 simulations,
## one can still observe noise in Bayesian computation. One possible reason
## is the following:   
den4 <- gpda::n1PDF(data, b=.09, A=.07, mean_v=c(-7.37, -4.36), 
sd_v=c(1, 1), t0=.94, nsim=2^20)

\dontrun{
den5 <- rtdists::n1PDF(data, b=.09, A=.07, mean_v=c(-7.37, -4.36), 
sd_v=c(1, 1), t0=.94, silent=T)
par(mfrow=c(1,2))
plot(data,  den4, type="l")
lines(data, den5, lwd=1.5)

plot(data, den5,  type="l")
lines(data, den4, lwd=1.5)
all.equal(den4, den5)
## "Mean relative difference: 0.9991495"
}

## Note both shapes are similar, but dlba method estimates smaller values, 
## relative to rlba method. This happens in behaviourally less plausible  
## parameter sets. It takes longer iterations to smooth out the 
## noise.  That is when a sampler no longer propose these less plausible
## parameter sets. 
}
\references{
Brown, S. D., & Heathcote, A. (2008). The simplest complete model of choice 
response time: Linear ballistic accumulation. Cognitive psychology, 57(3), 
153-178. \url{https://doi.org/10.1016/j.cogpsych.2007.12.002}
}
